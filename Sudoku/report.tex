\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023


% ready for submission
\usepackage[preprint]{neurips_2023}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2023}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2023}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2023}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{amsmath,amssymb}
\usepackage{listings,graphicx}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\title{Report for Programming Assignment 3 (Sudoku)}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{%
  Matthew Callahan\\
  \And
  Suphalerk Lortaraprasert
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}


\begin{document}


\maketitle


\begin{abstract}
  We solved the problem of SuDoKu with backtracking search. We used both simple backtracking search and various levels of inference procedures based on increasingly complicated models of the problem. We found that increasing the complexity of the models decreased the amount of backtracking required to solve various problems. We were able to solve medium and hard problems, but were unable to get the more complicated inference methods to work and were thus unable to solve the evil problems. 
 \end{abstract}

\section{Introduction}
SuDoKu is a challenge problem, being both a puzzle and a constraint satisfaction problem. In this game, each unit (rows, columns, and boxes) must adhere to the "all-diff" constraint, meaning every digit within a unit must be unique. The 81 squares on the SuDoKu grid are akin to variables, each with a domain from 1 to 9. Depending on the problem, various cells will also be forced to certain values. 

We implemented backtracking linesearch with several different levels of inference from the dynamics of the problems.  We iteratively added more and more advanced levels of inference as we tried more and more difficult problems. 

  
\section{Environment Descriptions}
\subsection{The board}
the board is a nine by nine grid with each row, column, and sub-three-by-three grid maintaining its own all-diff constraint. We implemented thiss with an array of sets in python. When an element was assigned to a cell, we removed that value from all the relavent neighbors. 
\subsection{Constraint propagation}
In the constraint propagation step, the SuDoKu board undergoes a series of rule applications in the following order. This process aims to systematically decrease the domain values associated with each variable:



\begin{description}
  \item[Rule 1:] If a cell has only one value remaining in its domain, assign that value to the cell.
  \item[Rule 2:] If a value x is not present in the domain of any other cell within the same row, column, or box as a particular cell, assign x to that cell.
  \item[Rule 3:] Identify k squares within any row, column, or box, where each square shares a domain containing the same k numbers or a subset of those numbers. Then, eliminate those k numbers from the domains of all other cells within that unit. This is referred to as the "naked double" and "naked triple" rule when k=2 and k=3, respectively.
\end{description}

\begin{algorithm}[h]
  
  \caption{propagateConstraints}
  \begin{algorithmic}
\While {True}
    \State {hits = self.doNakedSingles()}
    \If {hits > 0:}
        \State {continue}
    \EndIf
        \State {hits = self.doHiddenSingles()}
        \If {hits > 0:}
        \State {continue}
    \EndIf
    \If {self.rule == 2 or self.rule == 3:}
    \State {hits = self.doNakedPairs()}
    \If {hits > 0:}
    \State {continue}
\EndIf
    \State {hits = self.doHiddenPairs()}
    \If {hits > 0:}
    \State {continue}
    \EndIf
\EndIf
\If {self.rule == 3:}
 

   
    \State  {hits = self.doNakedTriples()}
    \If {hits > 0:}
    \State {continue}
\EndIf
            \State   {hits = self.doHiddenTriples()}
            \If {hits > 0:}
            \State {continue}
        \EndIf
        \EndIf  
            \State  {break}  
            \EndWhile
\end{algorithmic}
\label{alg:Constraint Propagation}
\end{algorithm}
 
   
   
 
 

\subsection{Backtracking Search}
Backtracking searches operate similarly to depth-first search algorithms. In each iteration, the system selects variables for configuration. This is followed by constraint propagation. If a conflict arises after the spread The algorithm will retrace the steps. Withdraw a work assignment and explore alternatives, on the other hand, if the diffusion of restrictions is successful. The search will continue and the assignment will continue. This iterative process lasts until a comprehensive assignment that meets the puzzle criteria is found. or return a failure signal


\begin{algorithm}[h]
  
  \caption{Backtracking Search}
  \begin{algorithmic}
 \If { board has no empty cells: }
    \State return board, 0  
  \EndIf
  \If { not forwardCheck(board) }
    \State return None, 0   
  \EndIf
       
  \State propagateConstraints(board)

  \If { board has no empty cells }
    \State return board, 0   
  \EndIf
  

  \State (fillX, fillY) = mostConstrainedVariable(board)
  \State backup = copy(board)
  \State moveDomain = copy(backup.cells[fillX][fillY])
  \State runMoves = copy(backup)
  \State backtracks = 0



  \For {move in moveDomain:}
  \If {fillCell(runMoves, fillX, fillY, move) == -1:}
      \State {continue }
      \EndIf

      \If {not forwardCheck(runMoves)}
      \State {runMoves = copy(backup)}

      \State {backtracks += 1}

      \State {continue }
      \EndIf
      \State {solution, backs = recursiveConstrained(runMoves)}
      \State {backtracks += backs}



      \If {if solution is not None}
      \State return solution, backtracks
      \EndIf

      \State {runMoves = copy(backup)}
      \State {backtracks += 1  }
      \EndFor
  \State return None, 0           
    
         \end{algorithmic}
 \label{alg:Backtracking Search}
\end{algorithm}


 
 

\section{Experimental setup}
Sudoku Puzzles: Prepare a set of Sudoku puzzles of varying difficulty levels (easy, medium, hard, and expert).

Inference Rules Implementation: Ensure each inference rule (Naked Singles, Hidden Singles, Naked Pairs, Hidden Pairs, Naked Triples, Hidden Triples) is implemented correctly.

Rule Subsets: Define the subsets of rules to be tested:
No inference
Naked and Hidden Singles
Naked and Hidden Singles and Pairs
Naked and Hidden Singles, Pairs, and Triples
\subsection{Inference Rules Explanation
}
{Naked Singles: If a cell has only one possible candidate, that candidate must be the solution for that cell.}

{Hidden Singles: If a candidate appears only once in a row, column, or block, it must be the solution for that cell.}

{Naked Pairs: If two cells in a unit (row, column, or block) contain the same two candidates and no others, those candidates can be removed from other cells in that unit.}

{Hidden Pairs: If two candidates are the only ones that can go into two cells within a unit, those cells must contain these two candidates.}

{Naked Triples: If three cells in a unit contain only the same three candidates and no others, those candidates can be removed from other cells in that unit.}

{Hidden Triples: If three candidates are restricted to exactly three cells in a unit, those cells must contain these three candidates.}


\subsection{Fixed  Baseline}
For this case, we selected the  cell to fill in in an arbitrary, consistent order while propogating constraints forward after each action and also remoing entries filled in by hidden and naked singles inference rules. 
\subsection{Most Constrained Variable}
For this case, after running through all the inference rules we would select the cell with the least number of choices (after implementing our first set of inference rules this would always be at least two choices, but before then it could be 1). 

\section{Results}
We ran the easy problems through both versions of variable selection without any inference rules other than forward checking. The results of these experiments can be seen in Table ~\ref{tab:resultsEasy}. Since we achieved zero backtracks with these puzzles without any affitional inference rules, we did not rerun them with more rules.

For the medium and hard puzzles, we were sometimes able to achieve no backtracking with just the singles inference rules, but not always. Those that could be solved with just the singles inference rules are found in Table~\ref{tab:firstInferences}.
\subsection{Backtracking}
In general, the harder problems required more complicated rules to bound the backtracking. Also, using a fixed order to fill in the cells was strictly worse than using the most-constrained variable.

The experts who grade the problems seem to do a poor job of it. Some medium problems could be solved without backtracking with the same level of rules as used in the easy problems, the same for hard and medium. Also, sometimes with the same set of rules the medium problems would require more backtracking than the hard problems.
 \subsection{Runtime Performance}
 The solving time would either take longer than we were willing to wait for a solution, in the case that not enough rules were used, or the problem would be solved in too little time for a human to notice. 
\begin{table}[h]\centering
  \begin{tabular}{lll}
    \toprule
    puzzle number& Arbitrary Order Backtracks & Most Constrained Variable Backtracks\\
    \midrule
    1& 5 & 0\\
    \midrule
    6& 13&0\\
    \midrule
    7& 10&0\\
    \midrule
    20&10&0\\
    \midrule
    30& 8&0\\
    \midrule
    41& 12& 0\\
    \midrule
    42& 6& 0\\
    \midrule
    43& 13&0\\
    \midrule
    44&9&0\\
    \midrule
    50&6&0\\
    \midrule
    55 &11 &0\\
    \midrule
    61& 11 &0\\
    \midrule
    62 &5&0\\
    \midrule
    67&7&0\\
    \midrule
    68& 5&0\\
    \midrule
    69&7&0\\
    \midrule
    70& 12 &1\\
    \bottomrule
  \end{tabular}
  \caption{Number of backtracks for various algorithms for the easy puzzles. These algorithms did not use any of the inference rules besides forward checking. }
  \label{tab:resultsEasy}
\end{table}
\begin{table}[h]
  \centering
  \begin{tabular}{lll}
   \toprule
    puzzle number& Arbitrary Order Backtracks & Most Constrained Variable Backtracks\\
    \midrule
    2&9&0\\
    \midrule
    3&15&0\\
    \midrule
    8&15&6\\
    \midrule
    10&10&3\\
    \midrule
    11&13&2\\
    \midrule
    12&12&1\\
    \midrule
    13&21&3\\
    \midrule
    21&12&1\\
    \midrule
    22&6&2\\
    \midrule
    23&13&4\\
    \midrule
    24&16&1\\
    \midrule
    26&11&3\\
    \midrule
    31&8&0\\
    \midrule
    32&16&5\\
    \midrule
    33&10&0\\
    \midrule
    36&8&0\\
    \midrule
    37&16&2\\
    \midrule
    38&15&5\\
    \midrule
    45&8&0\\
    \midrule
    46&11&0\\
    \midrule
    47&10&0\\
    \midrule
    53&11&0\\
    \midrule
    54&11&0\\
    \midrule
    56&13&4\\
    \midrule
    57&11&1\\
    \midrule
    58&14&2\\
    \midrule
    59&13&2\\
    \midrule
    63&9&1\\
    \midrule
    64&11&2\\
    \midrule
    65&11&0\\
    \midrule
    66&14&3\\
    \midrule
    71&15&4\\
    \midrule
    72&11&4\\
    \midrule
    73&22&2\\
    \midrule
    74&14&3\\
    \midrule
    75&15&8\\
    \midrule
    76&12&3\\
    \midrule
    77&16&5\\
           \bottomrule
  \end{tabular}
  \caption{Number of backtracks for each heuristic with the first two inference rules for various puzzles. As you can see the hard and medium difficulty level is not as well seperated, since both hard and medium puzzles show similar levels of backtracking under these rule assignments. The evil problems were not tested here because they were not solved in a resonable time.  }
  \label{tab:firstInferences}
\end{table}
\section{Discussion}
The problems listed as more difficult very broadly required more backtracking to solve. In addition, adding inference rules reduced the amount of backtracking required, but the most effective heuristic we found for reducing backtracking was to use most constrained variable ordering instead of an arbitrary ordering. 


  
\end{document}